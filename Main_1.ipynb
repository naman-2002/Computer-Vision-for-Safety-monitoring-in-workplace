{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71a99075-24a0-4b56-b98b-dbd044e86f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2002n\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, ttk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import threading\n",
    "import time\n",
    "from playsound import playsound\n",
    "import numpy as np\n",
    "from keras.utils import img_to_array\n",
    "from collections import deque\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import csv\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9364e5c-32ad-4c89-87c0-6c608af23e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2002n\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 16 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "# Load YOLOv8 model\n",
    "yolo_model = YOLO('E:/Download Till 27-07-2024/Downloads/yolov8_model.pt')\n",
    "\n",
    "# Load ConvLSTM model\n",
    "convlstm_model = load_model('D:/my_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf157835-ede4-4981-b56d-991708534162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 3837.7ms\n",
      "Speed: 267.4ms preprocess, 3837.7ms inference, 598.8ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 458.2ms\n",
      "Speed: 0.0ms preprocess, 458.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 449.1ms\n",
      "Speed: 15.6ms preprocess, 449.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 484.3ms\n",
      "Speed: 15.9ms preprocess, 484.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 463.2ms\n",
      "Speed: 15.6ms preprocess, 463.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 420.6ms\n",
      "Speed: 15.6ms preprocess, 420.6ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 470.1ms\n",
      "Speed: 15.6ms preprocess, 470.1ms inference, 7.1ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 421.2ms\n",
      "Speed: 11.1ms preprocess, 421.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 426.6ms\n",
      "Speed: 10.2ms preprocess, 426.6ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 485.4ms\n",
      "Speed: 5.6ms preprocess, 485.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 471.0ms\n",
      "Speed: 10.2ms preprocess, 471.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 474.8ms\n",
      "Speed: 10.7ms preprocess, 474.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 468.9ms\n",
      "Speed: 12.2ms preprocess, 468.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 483.1ms\n",
      "Speed: 20.6ms preprocess, 483.1ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 489.6ms\n",
      "Speed: 10.2ms preprocess, 489.6ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 491.1ms\n",
      "Speed: 11.4ms preprocess, 491.1ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 474.0ms\n",
      "Speed: 10.6ms preprocess, 474.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 460.0ms\n",
      "Speed: 10.1ms preprocess, 460.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 504.8ms\n",
      "Speed: 10.3ms preprocess, 504.8ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 471.3ms\n",
      "Speed: 10.7ms preprocess, 471.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 459.0ms\n",
      "Speed: 10.7ms preprocess, 459.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 427.9ms\n",
      "Speed: 10.4ms preprocess, 427.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 401.5ms\n",
      "Speed: 10.7ms preprocess, 401.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 433.1ms\n",
      "Speed: 15.9ms preprocess, 433.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 452.2ms\n",
      "Speed: 0.0ms preprocess, 452.2ms inference, 15.9ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 454.6ms\n",
      "Speed: 15.6ms preprocess, 454.6ms inference, 15.9ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 469.7ms\n",
      "Speed: 0.0ms preprocess, 469.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 488.2ms\n",
      "Speed: 15.6ms preprocess, 488.2ms inference, 8.2ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 468.1ms\n",
      "Speed: 15.6ms preprocess, 468.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 470.1ms\n",
      "Speed: 15.6ms preprocess, 470.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 453.7ms\n",
      "Speed: 15.6ms preprocess, 453.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 481.5ms\n",
      "Speed: 15.6ms preprocess, 481.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 466.7ms\n",
      "Speed: 15.6ms preprocess, 466.7ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 462.5ms\n",
      "Speed: 16.5ms preprocess, 462.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 463.4ms\n",
      "Speed: 0.0ms preprocess, 463.4ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 468.9ms\n",
      "Speed: 16.0ms preprocess, 468.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 477.9ms\n",
      "Speed: 15.6ms preprocess, 477.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 468.6ms\n",
      "Speed: 15.6ms preprocess, 468.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 446.2ms\n",
      "Speed: 15.6ms preprocess, 446.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 468.2ms\n",
      "Speed: 0.0ms preprocess, 468.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 461.8ms\n",
      "Speed: 15.6ms preprocess, 461.8ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 458.7ms\n",
      "Speed: 15.6ms preprocess, 458.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 451.8ms\n",
      "Speed: 15.6ms preprocess, 451.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 452.4ms\n",
      "Speed: 0.0ms preprocess, 452.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 449.7ms\n",
      "Speed: 15.6ms preprocess, 449.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 1 safe_walkway, 497.4ms\n",
      "Speed: 0.0ms preprocess, 497.4ms inference, 16.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 451.1ms\n",
      "Speed: 0.0ms preprocess, 451.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 437.8ms\n",
      "Speed: 0.0ms preprocess, 437.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 341.7ms\n",
      "Speed: 16.6ms preprocess, 341.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 360.8ms\n",
      "Speed: 15.6ms preprocess, 360.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 357.7ms\n",
      "Speed: 15.6ms preprocess, 357.7ms inference, 8.1ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 opened_panel, 363.7ms\n",
      "Speed: 15.6ms preprocess, 363.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n"
     ]
    }
   ],
   "source": [
    "#better bounding box with good gui\n",
    "\n",
    "# Parameters\n",
    "sequence_len = 10\n",
    "min_analysis_frames = 3\n",
    "frame_size = (64, 64)\n",
    "class_map = {0: 'opened_panel', 1: 'unauthorized_intervention', \n",
    "             2: 'overload_forklift', 3: 'unsafe_walkway'}\n",
    "unsafe_labels_yolo = ['opened_panel', 'unauthorized_intervention', \n",
    "                     'overload_forklift', 'unsafe_walkway']\n",
    "\n",
    "# Safety statistics\n",
    "safety_stats = {\n",
    "    'total_frames': 0,\n",
    "    'safe_frames': 0,\n",
    "    'unsafe_events': 0,\n",
    "    'last_alert': None,\n",
    "    'alert_count': 0\n",
    "}\n",
    "\n",
    "def is_unsafe_yolo(frame):\n",
    "    results = yolo_model(frame)[0]\n",
    "    class_ids = results.boxes.cls.int().tolist()\n",
    "    confidences = results.boxes.conf.tolist()\n",
    "    detected_classes = [results.names[i] for i in class_ids]\n",
    "    return results, any(cls in unsafe_labels_yolo for cls in detected_classes)\n",
    "\n",
    "def predict_unsafe_behavior(buffer):\n",
    "    sequence = [cv2.resize(f, frame_size) for f in buffer]\n",
    "    sequence = [img_to_array(f) / 255.0 for f in sequence]\n",
    "    sequence = np.expand_dims(np.array(sequence), axis=0)\n",
    "    preds = convlstm_model.predict(sequence, verbose=0)\n",
    "    return np.argmax(preds)\n",
    "\n",
    "class SafetyMonitorApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"AI Workplace Safety Monitoring\")\n",
    "        self.root.geometry(\"1280x860\")\n",
    "        self.root.configure(bg=\"#121420\")\n",
    "\n",
    "        # Header\n",
    "        tk.Label(root, text=\"AI-Powered Workplace Monitoring\", \n",
    "                font=(\"Arial\", 20, \"bold\"), bg=\"#121420\", fg=\"cyan\").place(x=400, y=10)\n",
    "\n",
    "        # Video display\n",
    "        self.video_label = tk.Label(root, bg=\"#121420\")\n",
    "        self.video_label.place(x=40, y=60, width=720, height=480)\n",
    "\n",
    "        # Status panel\n",
    "        self.status_label = tk.Label(root, text=\"Status: Waiting for video...\", \n",
    "                                   font=(\"Arial\", 14), bg=\"#121420\", fg=\"white\")\n",
    "        self.status_label.place(x=800, y=60)\n",
    "\n",
    "        # Event log\n",
    "        self.log_box = tk.Text(root, height=12, width=50, state='disabled', \n",
    "                             bg=\"#1e1e2f\", fg=\"white\", font=(\"Consolas\", 10))\n",
    "        self.log_box.place(x=800, y=100)\n",
    "\n",
    "        # Buttons frame\n",
    "        btns = tk.Frame(root, bg=\"#121420\")\n",
    "        btns.place(x=800, y=340)\n",
    "        self.load_btn = tk.Button(btns, text=\"Load Video\", command=self.load_video, \n",
    "                                bg=\"#2e2e4f\", fg=\"white\", width=25)\n",
    "        self.load_btn.grid(row=0, column=0, pady=5)\n",
    "\n",
    "        # Safety statistics dashboard\n",
    "        stats_frame = tk.Frame(root, bg=\"#1e1e2f\", bd=2, relief=tk.RIDGE)\n",
    "        stats_frame.place(x=40, y=550, width=720, height=280)\n",
    "        \n",
    "        tk.Label(stats_frame, text=\"SAFETY STATISTICS\", font=(\"Arial\", 12, \"bold\"), \n",
    "                bg=\"#1e1e2f\", fg=\"cyan\").pack(pady=5)\n",
    "        \n",
    "        # Progress bars for statistics\n",
    "        self.safety_meter = ttk.Progressbar(stats_frame, length=680, \n",
    "                                           mode='determinate', maximum=100)\n",
    "        self.safety_meter.pack(pady=5)\n",
    "        self.safety_label = tk.Label(stats_frame, text=\"Safety Level: 100%\", \n",
    "                                    font=(\"Arial\", 10), bg=\"#1e1e2f\", fg=\"white\")\n",
    "        self.safety_label.pack()\n",
    "        \n",
    "        # Counters\n",
    "        counters_frame = tk.Frame(stats_frame, bg=\"#1e1e2f\")\n",
    "        counters_frame.pack(pady=10)\n",
    "        \n",
    "        tk.Label(counters_frame, text=\"Total Frames:\", font=(\"Arial\", 10), \n",
    "                bg=\"#1e1e2f\", fg=\"white\").grid(row=0, column=0, padx=5)\n",
    "        self.total_frames_label = tk.Label(counters_frame, text=\"0\", font=(\"Arial\", 10, \"bold\"), \n",
    "                                         bg=\"#1e1e2f\", fg=\"white\")\n",
    "        self.total_frames_label.grid(row=0, column=1, padx=5)\n",
    "        \n",
    "        tk.Label(counters_frame, text=\"Safe Frames:\", font=(\"Arial\", 10), \n",
    "                bg=\"#1e1e2f\", fg=\"white\").grid(row=1, column=0, padx=5)\n",
    "        self.safe_frames_label = tk.Label(counters_frame, text=\"0\", font=(\"Arial\", 10, \"bold\"), \n",
    "                                        bg=\"#1e1e2f\", fg=\"green\")\n",
    "        self.safe_frames_label.grid(row=1, column=1, padx=5)\n",
    "        \n",
    "        tk.Label(counters_frame, text=\"Unsafe Events:\", font=(\"Arial\", 10), \n",
    "                bg=\"#1e1e2f\", fg=\"white\").grid(row=2, column=0, padx=5)\n",
    "        self.unsafe_events_label = tk.Label(counters_frame, text=\"0\", font=(\"Arial\", 10, \"bold\"), \n",
    "                                          bg=\"#1e1e2f\", fg=\"red\")\n",
    "        self.unsafe_events_label.grid(row=2, column=1, padx=5)\n",
    "        \n",
    "        # Alert controls\n",
    "        self.alarm_enabled = tk.BooleanVar(value=True)\n",
    "        tk.Checkbutton(stats_frame, text=\"Enable Alarms\", variable=self.alarm_enabled, \n",
    "                      font=(\"Arial\", 10), bg=\"#1e1e2f\", fg=\"white\", selectcolor=\"#121420\").pack(pady=5)\n",
    "\n",
    "        self.stop_flag = False\n",
    "        self.alarm_on = False\n",
    "        self.csv_file = open(\"unsafe_events_log.csv\", mode='w', newline='')\n",
    "        self.csv_writer = csv.writer(self.csv_file)\n",
    "        self.csv_writer.writerow([\"Timestamp\", \"Label\", \"Frame Position\"])\n",
    "\n",
    "    def load_video(self):\n",
    "        video_path = filedialog.askopenfilename()\n",
    "        if video_path:\n",
    "            # Reset statistics when loading new video\n",
    "            global safety_stats\n",
    "            safety_stats = {\n",
    "                'total_frames': 0,\n",
    "                'safe_frames': 0,\n",
    "                'unsafe_events': 0,\n",
    "                'last_alert': None,\n",
    "                'alert_count': 0\n",
    "            }\n",
    "            self.update_stats_display()\n",
    "            threading.Thread(target=self.process_video, args=(video_path,), daemon=True).start()\n",
    "\n",
    "    def update_stats_display(self):\n",
    "        total = max(1, safety_stats['total_frames'])\n",
    "        safety_percent = (safety_stats['safe_frames'] / total) * 100\n",
    "        \n",
    "        self.safety_meter['value'] = safety_percent\n",
    "        self.safety_label.config(text=f\"Safety Level: {safety_percent:.1f}%\")\n",
    "        self.total_frames_label.config(text=str(safety_stats['total_frames']))\n",
    "        self.safe_frames_label.config(text=str(safety_stats['safe_frames']))\n",
    "        self.unsafe_events_label.config(text=str(safety_stats['unsafe_events']))\n",
    "        \n",
    "        # Change color based on safety level\n",
    "        if safety_percent > 80:\n",
    "            self.safety_meter['style'] = 'green.Horizontal.TProgressbar'\n",
    "        elif safety_percent > 50:\n",
    "            self.safety_meter['style'] = 'yellow.Horizontal.TProgressbar'\n",
    "        else:\n",
    "            self.safety_meter['style'] = 'red.Horizontal.TProgressbar'\n",
    "\n",
    "    def log_event(self, message, label, frame_position):\n",
    "        timestamp = time.strftime(\"%H:%M:%S\")\n",
    "        log_message = f\"[{timestamp}] {message} (Label: {label}, Frame: {frame_position})\"\n",
    "        self.log_box.config(state='normal')\n",
    "        self.log_box.insert(tk.END, log_message + \"\\n\")\n",
    "        self.log_box.see(tk.END)\n",
    "        self.log_box.config(state='disabled')\n",
    "        self.csv_writer.writerow([timestamp, label, frame_position])\n",
    "\n",
    "    def play_alarm(self):\n",
    "        if not self.alarm_on and self.alarm_enabled.get():\n",
    "            self.alarm_on = True\n",
    "            try:\n",
    "                playsound(\"D:/beep.wav\")\n",
    "            except Exception as e:\n",
    "                print(\"Alarm error:\", e)\n",
    "            self.alarm_on = False\n",
    "\n",
    "    def process_video(self, video_path):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frame_buffer = deque(maxlen=sequence_len)\n",
    "        frame_count = 0\n",
    "\n",
    "        while cap.isOpened() and not self.stop_flag:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            frame_count += 1\n",
    "            safety_stats['total_frames'] += 1\n",
    "            \n",
    "            if frame_count % 2 != 0:\n",
    "                continue\n",
    "\n",
    "            display_frame = frame.copy()\n",
    "            results, is_unsafe = is_unsafe_yolo(frame)\n",
    "            \n",
    "            # Draw all detections with improved visibility\n",
    "            for box, cls, conf in zip(results.boxes.xyxy, results.boxes.cls, results.boxes.conf):\n",
    "                x1, y1, x2, y2 = map(int, box[:4])\n",
    "                class_name = results.names[int(cls)]\n",
    "                confidence = float(conf)\n",
    "                \n",
    "                # Set colors and thickness\n",
    "                color = (0, 0, 255) if class_name in unsafe_labels_yolo else (0, 255, 0)\n",
    "                box_thickness = 2\n",
    "                text_thickness = 2\n",
    "                font_scale = 0.8  # Increased font size\n",
    "                \n",
    "                # Draw bounding box\n",
    "                cv2.rectangle(display_frame, (x1, y1), (x2, y2), color, box_thickness)\n",
    "                \n",
    "                # Create text label\n",
    "                label = f\"{class_name} {confidence:.2f}\"\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                \n",
    "                # Calculate text size\n",
    "                (text_width, text_height), _ = cv2.getTextSize(label, font, font_scale, text_thickness)\n",
    "                \n",
    "                # Text background position (ensure it stays in frame)\n",
    "                text_bg_x1 = x1\n",
    "                text_bg_y1 = y1 - text_height - 10  # Don't go above top\n",
    "                text_bg_x2 = x1 + text_width\n",
    "                text_bg_y2 = y1\n",
    "\n",
    "                if text_bg_y1 < 0:\n",
    "                    text_bg_y1 = y1 + text_height + 10\n",
    "                    text_bg_y2 = y1\n",
    "\n",
    "                cv2.putText(display_frame, label, (x1, y1 - 5), \n",
    "                           font, font_scale, (0, 0, 0), text_thickness + 2)  # Black outline\n",
    "                cv2.putText(display_frame, label, (x1, y1 - 5), \n",
    "                           font, font_scale, (255, 255, 255), text_thickness)  # White text\n",
    "                \n",
    "                # Draw filled background\n",
    "                cv2.rectangle(display_frame, \n",
    "                             (text_bg_x1, text_bg_y1),\n",
    "                             (text_bg_x2, text_bg_y2), \n",
    "                             color, -1)\n",
    "\n",
    "            resized_frame = cv2.resize(display_frame, (720, 480))\n",
    "\n",
    "            if is_unsafe:\n",
    "                frame_buffer.append(frame)\n",
    "    \n",
    "                # Only analyze every 2nd unsafe frame when we have enough\n",
    "                if len(frame_buffer) >= min_analysis_frames and frame_count % 3 == 0:\n",
    "                    # Use actual frames only (no padding)\n",
    "                    actual_frames = list(frame_buffer)\n",
    "        \n",
    "                    # If we must have exact sequence_len, use smarter sampling:\n",
    "                    if len(actual_frames) >= sequence_len:\n",
    "                        # Take every nth frame to get sequence_len frames\n",
    "                        step = len(actual_frames) // sequence_len\n",
    "                        analysis_frames = actual_frames[::step][:sequence_len]\n",
    "                    else:\n",
    "                        analysis_frames = actual_frames\n",
    "            \n",
    "                        pred_class = predict_unsafe_behavior(analysis_frames)\n",
    "                    label = class_map.get(pred_class, \"Unknown\")\n",
    "\n",
    "                    if pred_class != 0:\n",
    "                        # Update statistics\n",
    "                        safety_stats['unsafe_events'] += 1\n",
    "                        \n",
    "                        # Add main warning text\n",
    "                        cv2.putText(resized_frame, f\"UNSAFE: {label}\", (10, 40),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)\n",
    "                        self.status_label.config(text=f\"Status: {label} detected!\", fg=\"red\")\n",
    "                        self.log_event(f\"UNSAFE behavior detected\", label, frame_count)\n",
    "                        \n",
    "                        # Trigger alarm (with cooldown)\n",
    "                        current_time = time.time()\n",
    "                        if (safety_stats['last_alert'] is None or \n",
    "                            (current_time - safety_stats['last_alert']) > 5):  # 5 second cooldown\n",
    "                            threading.Thread(target=self.play_alarm, daemon=True).start()\n",
    "                            safety_stats['last_alert'] = current_time\n",
    "                            safety_stats['alert_count'] += 1\n",
    "            else:\n",
    "                safety_stats['safe_frames'] += 1\n",
    "                self.status_label.config(text=\"Status: Safe\", fg=\"green\")\n",
    "                frame_buffer.clear()\n",
    "\n",
    "            # Update statistics display\n",
    "            self.update_stats_display()\n",
    "            \n",
    "            # Convert for display in Tkinter\n",
    "            frame_rgb = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB)\n",
    "            img = Image.fromarray(frame_rgb)\n",
    "            imgtk = ImageTk.PhotoImage(image=img)\n",
    "            self.video_label.imgtk = imgtk\n",
    "            self.video_label.configure(image=imgtk)\n",
    "            self.video_label.update()\n",
    "\n",
    "        cap.release()\n",
    "        self.status_label.config(text=\"Status: Video Completed\", fg=\"white\")\n",
    "        self.csv_file.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    \n",
    "    # Configure progressbar style\n",
    "    style = ttk.Style()\n",
    "    style.theme_use('clam')\n",
    "    style.configure('green.Horizontal.TProgressbar', background='green')\n",
    "    style.configure('yellow.Horizontal.TProgressbar', background='yellow')\n",
    "    style.configure('red.Horizontal.TProgressbar', background='red')\n",
    "    \n",
    "    app = SafetyMonitorApp(root)\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03411551-6fd6-4484-9961-39993048084b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
